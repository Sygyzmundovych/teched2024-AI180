{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33c98819",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d71c6",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144ea36e",
   "metadata": {},
   "source": [
    "Before requests to orchestration can be issued, we need to provide authentication details to the SDK. This can be done either via a configuration file or via the environment. Make sure to check out the [SAP generative AI hub SDK project description](https://pypi.org/project/generative-ai-hub-sdk/) for more details. Below you will find an example for authenticating via environment variables using this very notebook.\n",
    "\n",
    "> **WARNING:**\n",
    "> Below code should never be used in production scenarios and is only for the purpose of illustrating which environment variables to use!\n",
    "> Credentials should never be defined in code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69d9183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../aicore_proxy_participant_credentials_ai180p104road.json', 'r') as file:\n",
    "    conn_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ff3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b125dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AICORE_AUTH_URL\"] = conn_data[\"python\"][\"AICORE_AUTH_URL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb65d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AICORE_AUTH_URL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058eac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AICORE_AUTH_URL\"] = conn_data[\"python\"][\"AICORE_AUTH_URL\"]\n",
    "os.environ[\"AICORE_BASE_URL\"] = conn_data[\"python\"][\"AICORE_BASE_URL\"]\n",
    "os.environ[\"AICORE_CLIENT_ID\"] = conn_data[\"python\"][\"AICORE_CLIENT_ID\"]\n",
    "os.environ[\"AICORE_CLIENT_SECRET\"] = conn_data[\"python\"][\"AICORE_CLIENT_SECRET\"]\n",
    "os.environ[\"AICORE_ORCHESTRATION_DEPLOYMENT_URL\"] = conn_data[\"python\"][\"AICORE_ORCHESTRATION_DEPLOYMENT_URL\"]\n",
    "os.environ[\"AICORE_RESOURCE_GROUP\"] = conn_data[\"python\"][\"AICORE_RESOURCE_GROUP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a682210",
   "metadata": {},
   "source": [
    "You will need to authenticate in every exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be88a8-702a-452a-a1c5-64ac7c69f206",
   "metadata": {},
   "source": [
    "# Content Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082bc7c3-2519-4302-812b-9ccc74947ae8",
   "metadata": {},
   "source": [
    "Orchestration also supports content filtering to moderate input and output. For each, multiple filters can be applied that remove harmful content from texts. Depending on the filter, sensitivity of various types can be configured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712a76c2-cea5-4d27-9450-8e9e5abc6c9b",
   "metadata": {},
   "source": [
    "## Input Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f0ed1-1e3e-4cbc-b1c3-c2250c7efd62",
   "metadata": {},
   "source": [
    "Input filtering is handy for blocking out harmful content form e.g. user input. To make use of input filtering we first up need to define a basic pipeline again. We use a simple prompt template, that just passes text provided as a parameter to an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec261164-7bf2-4976-8419-4ceee9a246cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "\n",
    "llm = LLM(\n",
    "    name=\"gemini-1.5-flash\",\n",
    "    version=\"latest\",\n",
    "    parameters={\"max_tokens\": 256, \"temperature\": 0.2},\n",
    ")\n",
    "\n",
    "template = Template(messages=[UserMessage(\"{{?text}}\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68548f9a-f6bd-444c-8e79-4c81ad598784",
   "metadata": {},
   "source": [
    "Next up we will configure an AzureContentFilter using the corresponding SDK primitives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4357055f-d596-4f58-b348-fa5c5bae2a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.content_filter import AzureContentFilter\n",
    "\n",
    "content_filter = AzureContentFilter(\n",
    "    hate=0,\n",
    "    sexual=0,\n",
    "    self_harm=0,\n",
    "    violence=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2ed16-6049-4c1b-911c-cf7672800738",
   "metadata": {},
   "source": [
    "**Note:** The lower the sensitivity value the higher the sensitivity. Zero (0) corresponds to the highest degree of content moderation. For further information please check out: https://learn.microsoft.com/en-us/azure/ai-services/content-safety/concepts/harm-categories?tabs=warning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7ef7b2-9c8d-4e86-851c-0b85853d38be",
   "metadata": {},
   "source": [
    "Now that we have all modules defined, the only thing left to do is plugging everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53759219-6df3-41d0-8be0-9b4fd4bcc7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    "    input_filters=[\n",
    "        content_filter,\n",
    "    ],\n",
    ")\n",
    "\n",
    "orchestration_service = OrchestrationService(\n",
    "    api_url=os.environ[\"AICORE_ORCHESTRATION_DEPLOYMENT_URL\"],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0f422-3610-4383-b6a1-ac82e9882d72",
   "metadata": {},
   "source": [
    "If the content filter detects a violation when performing an inference an error of type `OrchestrationError` will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29d6513-1a63-4326-9dbb-0c6ead10e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.exceptions import OrchestrationError\n",
    "\n",
    "try:\n",
    "    result = orchestration_service.run(\n",
    "        template_values=[\n",
    "            TemplateValue(\n",
    "                name=\"text\",\n",
    "                value=\"This is a hateful text!\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "except OrchestrationError as error:\n",
    "    print(error.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca10a5-b9d3-4c02-ac91-0b1c6c2eb009",
   "metadata": {},
   "source": [
    "The filter can be cleared by adjusting the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a531ce-5954-476f-8b49-af4cd5cd28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = orchestration_service.run(\n",
    "    template_values=[\n",
    "        TemplateValue(\n",
    "            name=\"text\",\n",
    "            value=\"This is a peaceful text!\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b2cd93-5e89-497e-892c-a8f9d3c2f759",
   "metadata": {},
   "source": [
    "## Output Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e56ffd-53a0-4914-a7f9-a2411a516064",
   "metadata": {},
   "source": [
    "Similarly, also LLM output can be filtered. We will just use our already created filter and apply it to the LLM output within the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf0b75f-517e-49e6-a9a2-af20140b40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestration_service.config.output_filters = [content_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75acc334-0cec-4311-b3bf-0964f0b0ec5e",
   "metadata": {},
   "source": [
    "Now let's try out if the filter works by prompting for an inherently violent lyrics from Johann Wolfgang von Goethe. Even though the version recited by the LLM might differ from the most common version, it should contain some form of suggested violence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47c472-7973-45c3-951a-aadc98f67c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = orchestration_service.run(\n",
    "    template_values=[\n",
    "        TemplateValue(\n",
    "            name=\"text\",\n",
    "            value='Provide the lyrics of the ballad \"Erlkönig\" from Johann Wolfgang von Goethe in German and English.',\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97147b02-65ac-4c54-85d9-f4881f847d54",
   "metadata": {},
   "source": [
    "**Note:** The behavior will differ from the input filter. Instead of raising an error, the returned content will be empty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ead618-db88-46b7-a278-635b732b0e31",
   "metadata": {},
   "source": [
    "Feel free to try around with AzureContentFilter settings. If you set sensitivity for violence to 4 you will be able to read the lyrics of Erlkönig."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30dd10-bab1-4afd-964a-92707824faac",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f599416-cc0b-44eb-9412-cd6dd97e0663",
   "metadata": {},
   "source": [
    "In this exercise you learned how content filtering can be applied to input and output using orchestration. Now let's combine capabilities into a more complex scenario. Continue to [Exercise 3 - Orchestration Chatbot](./ex3.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
